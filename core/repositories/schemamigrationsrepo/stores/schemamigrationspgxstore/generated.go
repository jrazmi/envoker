// Code generated by pgxstores. DO NOT EDIT.
// This file is ALWAYS REGENERATED - do not modify.
// For custom queries, see store.go which embeds the generated store.

package schemamigrationspgxstore

import (
	"bytes"
	"context"
	"errors"
	"fmt"
	"strings"
	"time"

	"github.com/jackc/pgx/v5"
	"github.com/jrazmi/envoker/core/repositories/schemamigrationsrepo"
	"github.com/jrazmi/envoker/core/scaffolding/fop"
	"github.com/jrazmi/envoker/infrastructure/postgresdb"
	"github.com/jrazmi/envoker/sdk/logger"
)

// ========================================
// GENERATED STORE
// ========================================

// GeneratedStore provides default implementations for all SchemaMigration SQL operations.
// Embed this struct in your custom Store (in store.go) to inherit default behavior
// that you can selectively override.
type GeneratedStore struct {
	log  *logger.Logger
	pool *postgresdb.Pool
}

// Create inserts a new SchemaMigration
func (s *GeneratedStore) Create(ctx context.Context, input schemamigrationsrepo.CreateSchemaMigration) (schemamigrationsrepo.SchemaMigration, error) {
	// PK is in Create struct - use value from input
	query := `INSERT INTO public.schema_migrations (version, checksum, applied_at) VALUES (@version, @checksum, @applied_at) RETURNING version, checksum, applied_at, created_at, updated_at`

	args := pgx.NamedArgs{
		"version":    input.Version,
		"checksum":   input.Checksum,
		"applied_at": input.AppliedAt,
	}

	rows, err := s.pool.Query(ctx, query, args)
	if err != nil {
		return schemamigrationsrepo.SchemaMigration{}, postgresdb.HandlePgError(err)
	}
	defer rows.Close()

	record, err := pgx.CollectOneRow(rows, pgx.RowToStructByName[schemamigrationsrepo.SchemaMigration])
	if err != nil {
		return schemamigrationsrepo.SchemaMigration{}, postgresdb.HandlePgError(err)
	}

	return record, nil
}

// Get retrieves a single SchemaMigration by ID
func (s *GeneratedStore) Get(ctx context.Context, version string) (schemamigrationsrepo.SchemaMigration, error) {
	query := `SELECT version, checksum, applied_at, created_at, updated_at FROM public.schema_migrations WHERE version = @version`

	args := pgx.NamedArgs{
		"version": version,
	}

	rows, err := s.pool.Query(ctx, query, args)
	if err != nil {
		return schemamigrationsrepo.SchemaMigration{}, postgresdb.HandlePgError(err)
	}
	defer rows.Close()

	record, err := pgx.CollectOneRow(rows, pgx.RowToStructByName[schemamigrationsrepo.SchemaMigration])
	if err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return schemamigrationsrepo.SchemaMigration{}, fmt.Errorf("SchemaMigration not found")
		}
		return schemamigrationsrepo.SchemaMigration{}, postgresdb.HandlePgError(err)
	}

	return record, nil
}

// Update modifies an existing SchemaMigration
func (s *GeneratedStore) Update(ctx context.Context, version string, input schemamigrationsrepo.UpdateSchemaMigration) error {
	buf := bytes.NewBufferString("UPDATE public.schema_migrations SET ")
	args := pgx.NamedArgs{
		"version": version,
	}
	var fields []string
	if input.Checksum != nil {
		fields = append(fields, "checksum = @checksum")
		args["checksum"] = *input.Checksum
	}
	if input.AppliedAt != nil {
		fields = append(fields, "applied_at = @applied_at")
		args["applied_at"] = *input.AppliedAt
	}

	// Always update the updated_at field
	now := time.Now().UTC()
	if input.UpdatedAt != nil {
		args["updated_at"] = *input.UpdatedAt
	} else {
		args["updated_at"] = now
	}
	fields = append(fields, "updated_at = @updated_at")

	// If no fields to update besides updated_at, return early
	if len(fields) == 1 {
		return fmt.Errorf("no fields to update")
	}

	// Join fields and complete the query
	buf.WriteString(strings.Join(fields, ", "))
	buf.WriteString(" WHERE version = @version")

	query := buf.String()
	s.log.DebugContext(ctx, "update SchemaMigration", "query", query, "version", version)

	result, err := s.pool.Exec(ctx, query, args)
	if err != nil {
		return postgresdb.HandlePgError(err)
	}

	if result.RowsAffected() == 0 {
		return fmt.Errorf("SchemaMigration not found")
	}

	return nil
}

// Delete removes a SchemaMigration by ID
func (s *GeneratedStore) Delete(ctx context.Context, version string) error {
	query := `DELETE FROM public.schema_migrations WHERE version = @version`

	args := pgx.NamedArgs{
		"version": version,
	}

	result, err := s.pool.Exec(ctx, query, args)
	if err != nil {
		return postgresdb.HandlePgError(err)
	}

	if result.RowsAffected() == 0 {
		return fmt.Errorf("SchemaMigration not found")
	}

	return nil
}

// List retrieves SchemaMigration records with filtering, ordering, and cursor pagination
func (s *GeneratedStore) List(ctx context.Context, filter schemamigrationsrepo.SchemaMigrationFilter, orderBy fop.By, page fop.PageStringCursor, forPrevious bool) ([]schemamigrationsrepo.SchemaMigration, error) {
	data := pgx.NamedArgs{}

	// Start building the query
	buf := bytes.NewBufferString(`
		SELECT
			version,
			checksum,
			applied_at,
			created_at,
			updated_at
		FROM
			public.schema_migrations`)

	// Apply filters
	s.applyFilter(filter, data, buf)

	// Setup configuration for string cursor pagination
	cursorConfig := postgresdb.StringCursorConfig{
		Cursor:     page.Cursor,
		OrderField: orderByFields[orderBy.Field],
		PKField:    "version",
		TableName:  "schema_migrations",
		Direction:  orderBy.Direction,
		Limit:      page.Limit,
	}

	// Apply cursor pagination
	if page.Cursor != "" {
		err := postgresdb.ApplyStringCursorPagination[time.Time](buf, data, cursorConfig, forPrevious)
		if err != nil {
			return nil, fmt.Errorf("cursorpagination: %s", err)
		}
	}

	// Add ordering
	err := postgresdb.AddOrderByClause(buf, cursorConfig.OrderField, cursorConfig.PKField, cursorConfig.Direction, forPrevious)
	if err != nil {
		return nil, fmt.Errorf("order: %w", err)
	}

	// Add limit
	postgresdb.AddLimitClause(cursorConfig.Limit, data, buf)

	// Execute the query
	query := buf.String()
	s.log.DebugContext(ctx, "list SchemaMigration", "query", query)

	rows, err := s.pool.Query(ctx, query, data)
	if err != nil {
		return nil, postgresdb.HandlePgError(err)
	}
	defer rows.Close()

	entities, err := pgx.CollectRows(rows, pgx.RowToStructByName[schemamigrationsrepo.SchemaMigration])
	if err != nil {
		return nil, postgresdb.HandlePgError(err)
	}

	// If we were getting previous page, reverse the results back to correct order
	if forPrevious && len(entities) > 0 {
		for i, j := 0, len(entities)-1; i < j; i, j = i+1, j-1 {
			entities[i], entities[j] = entities[j], entities[i]
		}
	}

	return entities, nil
}

// ========================================
// FILTER & ORDERING HELPERS
// ========================================

// orderByFields maps repository field names to database column names
var orderByFields = map[string]string{
	schemamigrationsrepo.OrderByPK:        "version",
	schemamigrationsrepo.OrderByCreatedAt: "created_at",
	schemamigrationsrepo.OrderByUpdatedAt: "updated_at",
	schemamigrationsrepo.OrderByChecksum:  "checksum",
	schemamigrationsrepo.OrderByAppliedAt: "applied_at",
}

// applyFilter applies query filters to the SQL query
func (s *GeneratedStore) applyFilter(filter schemamigrationsrepo.SchemaMigrationFilter, data pgx.NamedArgs, buf *bytes.Buffer) {
	var conditions []string
	// Filter by checksum
	if filter.Checksum != nil {
		conditions = append(conditions, "checksum = @checksum")
		data["checksum"] = *filter.Checksum
	}
	// Filter by applied_at
	if filter.AppliedAt != nil {
		conditions = append(conditions, "applied_at = @appliedAt")
		data["appliedAt"] = *filter.AppliedAt
	}
	// Filter by created_at - before
	if filter.CreatedAtBefore != nil {
		conditions = append(conditions, "created_at < @createdAt_before")
		data["createdAt_before"] = *filter.CreatedAtBefore
	}

	// Filter by created_at - after
	if filter.CreatedAtAfter != nil {
		conditions = append(conditions, "created_at > @createdAt_after")
		data["createdAt_after"] = *filter.CreatedAtAfter
	}
	// Filter by updated_at - before
	if filter.UpdatedAtBefore != nil {
		conditions = append(conditions, "updated_at < @updatedAt_before")
		data["updatedAt_before"] = *filter.UpdatedAtBefore
	}

	// Filter by updated_at - after
	if filter.UpdatedAtAfter != nil {
		conditions = append(conditions, "updated_at > @updatedAt_after")
		data["updatedAt_after"] = *filter.UpdatedAtAfter
	}

	// Search term across text fields
	if filter.SearchTerm != nil && *filter.SearchTerm != "" {
		searchPattern := "%" + *filter.SearchTerm + "%"
		searchConditions := []string{}
		searchConditions = append(searchConditions, "version ILIKE @search_term")
		searchConditions = append(searchConditions, "checksum ILIKE @search_term")
		if len(searchConditions) > 0 {
			conditions = append(conditions, "("+strings.Join(searchConditions, " OR ")+")")
			data["search_term"] = searchPattern
		}
	}

	// Apply conditions if any exist
	if len(conditions) > 0 {
		buf.WriteString(" WHERE ")
		buf.WriteString(strings.Join(conditions, " AND "))
	}
}
